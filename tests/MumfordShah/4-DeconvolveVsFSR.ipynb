{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between Deconvolution/Denoising and Fast Super-Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/Stage-SuperResolution/NAME-REPO.git\n",
    "# !mv NAME-REPO/* .\n",
    "# !rm -rf NAME-REPO\n",
    "# !pip install git+https://github.com/akhaten/lasp.git@COMPLETE-COMMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasp module\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import lasp.io\n",
    "import lasp.filters.linear\n",
    "import lasp.noise\n",
    "import lasp.convert\n",
    "import lasp.algorithm.experimental\n",
    "import lasp.thresholding\n",
    "import lasp.differential\n",
    "import lasp.utils\n",
    "\n",
    "# Other\n",
    "\n",
    "import scipy.signal\n",
    "import scipy.io.matlab\n",
    "import numpy\n",
    "import pandas\n",
    "import tqdm\n",
    "import pathlib\n",
    "import matplotlib.pyplot\n",
    "import typing\n",
    "\n",
    "IMAGE_PATH = pathlib.Path('./0-Images')\n",
    "# PATH = pathlib.Path('./3-LaplacianVersus')\n",
    "# if not(PATH.exists()):\n",
    "#     PATH.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test On"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decovolution/Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mumford_shah_deconv_v3(\n",
    "    y: numpy.ndarray, \n",
    "    h: numpy.ndarray, \n",
    "    alpha: float,\n",
    "    beta: float,\n",
    "    sigma: float,\n",
    "    nb_iterations: int,\n",
    "    tolerance: float,\n",
    "    error_history: list[float] = None\n",
    ") -> numpy.ndarray:\n",
    "\n",
    "    \"\"\"Mumford Shah\n",
    "    # TODO: make test\n",
    "    Solve argmin_{x} { (alpha/2) || y - Hx ||^2 + (beta/2) || nabla y ||^2 + || nabla y ||_1\n",
    "\n",
    "    Difference with v2 ?\n",
    "    We use Derivation in fourier space\n",
    "    and we set lap_diag = Dxt * Dx + Dyt * Dy and not laplacia  filter\n",
    "    \"\"\"\n",
    "\n",
    "    Dx_pad = lasp.utils.pad(numpy.array([[1, -1]]), y.shape)\n",
    "    Dx = numpy.fft.fft2(Dx_pad)\n",
    "    Dxt = numpy.conj(Dx)\n",
    "\n",
    "    Dy_pad = lasp.utils.pad(numpy.transpose(numpy.array([[1, -1]])), y.shape)\n",
    "    Dy = numpy.fft.fft2(Dy_pad)\n",
    "    Dyt = numpy.conj(Dy)\n",
    "\n",
    "    # Build kernel\n",
    "\n",
    "    Dx_diag = lasp.utils.fourier_diagonalization(\n",
    "        kernel = Dx_pad,\n",
    "        shape_out = y.shape \n",
    "    )\n",
    "    Dxt_diag = numpy.conj(Dx_diag)\n",
    "\n",
    "    Dy_diag = lasp.utils.fourier_diagonalization(\n",
    "        kernel = Dy_pad,\n",
    "        shape_out = y.shape \n",
    "    )\n",
    "    Dyt_diag = numpy.conj(Dy_diag)\n",
    "\n",
    "    lap_diag = Dxt_diag * Dx_diag + Dyt_diag * Dy_diag\n",
    "   \n",
    "   \n",
    "    h_diag = lasp.utils.fourier_diagonalization(\n",
    "        kernel = h,\n",
    "        shape_out = y.shape\n",
    "    )\n",
    "\n",
    "    h2_diag = numpy.abs(h_diag)**2\n",
    "\n",
    "\n",
    "    uker = alpha * h2_diag + (beta+sigma) * lap_diag\n",
    "\n",
    "    rhs1fft = alpha * numpy.conj(h_diag) * numpy.fft.fft2(y)\n",
    "\n",
    "    # Initialization\n",
    "    u = numpy.copy(y) \n",
    "    d_x=numpy.zeros_like(y)\n",
    "    d_y=numpy.zeros_like(y)\n",
    "    b_x=numpy.zeros_like(y)\n",
    "    b_y=numpy.zeros_like(y)\n",
    "\n",
    "    for _ in range(0, nb_iterations):\n",
    "\n",
    "        rhs2fft = sigma*Dxt*numpy.fft.fft2(d_x-b_x)+sigma*Dyt*numpy.fft.fft2(d_y-b_y)\n",
    "        rhsfft = rhs1fft + rhs2fft\n",
    "\n",
    "        u_prev = numpy.copy(u)\n",
    "\n",
    "        u_fft = rhsfft / uker\n",
    "        u = numpy.real(numpy.fft.ifft2(u_fft))    \n",
    "\n",
    "        err = numpy.linalg.norm(u-u_prev, 'fro') / numpy.linalg.norm(u, 'fro')\n",
    "        \n",
    "        if not(error_history is None):\n",
    "            error_history.append(err)\n",
    "\n",
    "        if err < tolerance:\n",
    "            break\n",
    "        \n",
    "    \n",
    "        u_dx = numpy.real(numpy.fft.ifft2(Dx * u_fft))\n",
    "        u_dy = numpy.real(numpy.fft.ifft2(Dy * u_fft))\n",
    "\n",
    "        d_x, d_y = lasp.thresholding.multidimensional_soft(\n",
    "            d = numpy.array(\n",
    "                [ \n",
    "                    u_dx + b_x, \n",
    "                    u_dy + b_y \n",
    "                ]\n",
    "            ),\n",
    "            epsilon = 1/sigma\n",
    "        )\n",
    "\n",
    "        b_x += (u_dx - d_x)\n",
    "        b_y += (u_dy - d_y)\n",
    "\n",
    "    u_normalized = lasp.utils.normalize(u)\n",
    "    \n",
    "    return u_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Super-Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mumford_shah_fsr(\n",
    "    y: numpy.ndarray, \n",
    "    h: numpy.ndarray, \n",
    "    alpha: float,\n",
    "    beta0: float,\n",
    "    beta1: float,\n",
    "    sigma: float,\n",
    "    d: int,\n",
    "    nb_iterations: int,\n",
    "    tolerance: float,\n",
    "    gamma: float = 0.,\n",
    "    error_history: list[float] = None\n",
    ") -> numpy.ndarray:\n",
    "\n",
    "\n",
    "    \"\"\"Mumford Shah\n",
    "    # TODO: make test\n",
    "    Solve $$argmin_{x} { (alpha/2) || y - Hx ||^2 + (beta0/2) || nabla y ||^2 + beta1 || nabla y ||_1$$\n",
    "\n",
    "    Params:\n",
    "        - y: low resolution\n",
    "        - h: deblur kernel\n",
    "        - alpha: hyper parameter of data fidelity\n",
    "        - beta0: hyper parameter of dirichlet energy\n",
    "        - beta1: hyper parameter of total variation\n",
    "        - sigma: split-bregman hyper parameter\n",
    "        - d: decimation\n",
    "        - nb_iterations: number of iteration\n",
    "        - tolerance: tolerance\n",
    "        - error_history: save errors of each iteration\n",
    "    \n",
    "    Returns:\n",
    "        - high resolution of y\n",
    "    \"\"\"\n",
    "\n",
    "    def block_mm(nr, nc, Nb, x1, order: str) -> numpy.ndarray:\n",
    "\n",
    "        block_shape = numpy.array([nr, nc])\n",
    "\n",
    "        x1 = lasp.utils.blockproc_reshape(x1, block_shape, order)\n",
    "        x1 = numpy.reshape(x1, newshape=(nr*nc, Nb), order=order)\n",
    "        x1 = numpy.sum(x1, axis=1)\n",
    "        x = numpy.reshape(x1, newshape=(nr, nc), order=order)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    # print(alpha, beta0, beta1)\n",
    "\n",
    "    y_rows, y_cols = y.shape\n",
    "\n",
    "    Dx_pad = lasp.utils.pad(numpy.array([[1, -1]]), (d*y_rows, d*y_cols))\n",
    "    Dx = numpy.fft.fft2(Dx_pad)\n",
    "    Dxt = numpy.conj(Dx)\n",
    "\n",
    "    Dy_pad = lasp.utils.pad(numpy.transpose(numpy.array([[1, -1]])), (d*y_rows, d*y_cols))\n",
    "    Dy = numpy.fft.fft2(Dy_pad)\n",
    "    Dyt = numpy.conj(Dy)\n",
    "\n",
    "    # Build kernel\n",
    "\n",
    "    Dx_diag = lasp.utils.fourier_diagonalization(\n",
    "        kernel = Dx_pad,\n",
    "        shape_out = (d*y_rows, d*y_cols)\n",
    "    )\n",
    "    Dxt_diag = numpy.conj(Dx_diag)\n",
    "\n",
    "    Dy_diag = lasp.utils.fourier_diagonalization(\n",
    "        kernel = Dy_pad,\n",
    "        shape_out = (d*y_rows, d*y_cols) \n",
    "    )\n",
    "    Dyt_diag = numpy.conj(Dy_diag)\n",
    "\n",
    "    lap_diag = Dxt_diag * Dx_diag + Dyt_diag * Dy_diag  + gamma\n",
    "   \n",
    "    h_diag = lasp.utils.fourier_diagonalization(\n",
    "        kernel = h,\n",
    "        shape_out = numpy.array([d*y_rows, d*y_cols])\n",
    "    )\n",
    "\n",
    "    h_diag_transp = numpy.conj(h_diag)\n",
    "\n",
    "    h2_diag = numpy.abs(h_diag)**2\n",
    " \n",
    "    STy = numpy.zeros(shape=(d*y_rows, d*y_cols))\n",
    "    STy[0::d, 0::d] = numpy.copy(y)\n",
    "    rhs1fft = alpha * h_diag_transp * numpy.fft.fft2(STy)\n",
    "\n",
    "\n",
    "    # Initialization\n",
    "    # import PIL.Image\n",
    "    # u = numpy.array(\n",
    "    #     PIL.Image.Image.resize(\n",
    "    #         PIL.Image.fromarray(y),\n",
    "    #         (y_rows*d, y_cols*d),\n",
    "    #         PIL.Image.Resampling.BICUBIC\n",
    "    #     )\n",
    "    # )\n",
    "    u = numpy.copy(y) \n",
    "    d_x=numpy.zeros_like(u)\n",
    "    d_y=numpy.zeros_like(u)\n",
    "    b_x=numpy.zeros_like(u)\n",
    "    b_y=numpy.zeros_like(u)\n",
    "\n",
    "    for _ in range(0, nb_iterations):\n",
    "\n",
    "        rhs2fft = sigma*Dxt*numpy.fft.fft2(d_x-b_x)+sigma*Dyt*numpy.fft.fft2(d_y-b_y)\n",
    "        rhsfft = rhs1fft + rhs2fft\n",
    "\n",
    "        u_prev = numpy.copy(u)\n",
    "\n",
    "        # Inverse\n",
    "        #u_fft = rhsfft / uker\n",
    "        ## Parameters\n",
    "        # fr = rhsfft\n",
    "        # fb = h_diag\n",
    "        # fbc = numpy.conj(h_diag)\n",
    "        # f2b = h2_diag\n",
    "        # nr, nc = y.shape\n",
    "        # m = nr * nc\n",
    "        # f2d = lap_diag\n",
    "        # nb = d*d\n",
    "        ##\n",
    "        # x1 = h_diag*rhsfft / lap_diag\n",
    "        x1 = h_diag*rhsfft / lap_diag\n",
    "        fbr = block_mm(y_rows, y_cols, d*d, x1, order='F')\n",
    "        # invW = block_mm(y.shape[0], y.shape[1], d*d, h2_diag / lap_diag, order='F')\n",
    "        invW = block_mm(y_rows, y_cols, d*d, h2_diag / lap_diag, order='F')\n",
    "        # invWBR = fbr / (invW + beta1*d*d)\n",
    "        invWBR = fbr / ( invW + (beta0+sigma) * (d*d / alpha) )\n",
    "        fun = lambda block : block*invWBR\n",
    "        FCBinvWBR = lasp.utils.blockproc(numpy.copy(h_diag_transp), numpy.array([y_rows, y_cols]), fun)\n",
    "        ## Returns\n",
    "        u_fft = (rhsfft - FCBinvWBR) / lap_diag\n",
    "        u_fft /= (beta0 + sigma)\n",
    "        # u_fft /= beta1\n",
    "        ##########\n",
    "        \n",
    "        # u_fft = rhsfft / uker\n",
    "\n",
    "        # Compute errors\n",
    "        u = numpy.real(numpy.fft.ifft2(u_fft))    \n",
    "\n",
    "        err = numpy.linalg.norm(u-u_prev, 'fro') / numpy.linalg.norm(u, 'fro')\n",
    "        \n",
    "        if not(error_history is None):\n",
    "            error_history.append(err)\n",
    "\n",
    "        if err < tolerance:\n",
    "            break\n",
    "        \n",
    "        \n",
    "        u_dx = numpy.real(numpy.fft.ifft2(Dx * u_fft))\n",
    "        u_dy = numpy.real(numpy.fft.ifft2(Dy * u_fft))\n",
    "\n",
    "\n",
    "        d_x, d_y = lasp.thresholding.multidimensional_soft(\n",
    "            d = numpy.array(\n",
    "                [ \n",
    "                    u_dx + b_x, \n",
    "                    u_dy + b_y \n",
    "                ]\n",
    "            ),\n",
    "            epsilon = beta1 / sigma\n",
    "        )\n",
    "\n",
    "        b_x += (u_dx - d_x)\n",
    "        b_y += (u_dy - d_y)\n",
    "\n",
    "    u_normalized = lasp.utils.normalize(u)\n",
    "\n",
    "    return u_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_from(params: pandas.Series) -> numpy.ndarray:\n",
    "\n",
    "    image_path = params['image']\n",
    "    blur = params['blur']\n",
    "    noise = params['noise']\n",
    "    \n",
    "    img = lasp.io.read(image_path)\n",
    "    out = numpy.copy(img)\n",
    "\n",
    "    if pandas.notna(blur):\n",
    "        kernel = lasp.filters.linear.gaussian_filter(size=blur[0], sigma=blur[1])\n",
    "        out = scipy.signal.convolve2d(out, kernel, mode='same')\n",
    "    \n",
    "    if pandas.notna(noise):\n",
    "        out = lasp.noise.awgn(out, snr=noise)\n",
    "\n",
    "    return out\n",
    "\n",
    "def add(\n",
    "    dataset: pandas.DataFrame,\n",
    "    image: pathlib.Path,\n",
    "    deblur_kernel: tuple[int, float],\n",
    "    alpha: float,\n",
    "    beta0: float,\n",
    "    beta1: float,\n",
    "    sigma: float,\n",
    "    d: int,\n",
    "    tol: float = 10**(-4),\n",
    "    iterations: int = 300,\n",
    "    noise: float = numpy.nan,\n",
    "    blur: tuple[int, float] = numpy.nan\n",
    ") -> pandas.DataFrame:\n",
    "\n",
    "    to_add = pandas.DataFrame(\n",
    "        {\n",
    "            'image' : [image], \n",
    "            'deblur_kernel' : [deblur_kernel], \n",
    "            'alpha' : [alpha], \n",
    "            'beta0' : [beta0],\n",
    "            'beta1' : [beta1],\n",
    "            'sigma' : [sigma],\n",
    "            'd' : [d],\n",
    "            'tol' : [tol], \n",
    "            'iterations' : [iterations], \n",
    "            'noise' : [noise],\n",
    "            'blur' : [blur]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return pandas.concat([dataset, to_add], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset() -> pandas.DataFrame:    \n",
    "    \n",
    "\n",
    "    dataset = pandas.DataFrame(\n",
    "        columns = [\n",
    "            'image' , 'deblur_kernel',\n",
    "            'alpha', 'beta0', 'beta1', 'sigma', 'd', # Hyper-parameters\n",
    "            'tol', 'iterations', # Iterative parameters\n",
    "            'noise',\n",
    "            'blur'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dataset = add(\n",
    "        dataset = dataset, \n",
    "        image = IMAGE_PATH / 'Baboon.bmp', deblur_kernel = (7, 3),\n",
    "        alpha = 100, beta0 = 1, beta1 = 1, sigma = 2, d = 1,\n",
    "        tol = 0, iterations = 10, \n",
    "        noise = lasp.convert.snrdb_to_snr(30),\n",
    "        blur = (7, 3)\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>deblur_kernel</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta0</th>\n",
       "      <th>beta1</th>\n",
       "      <th>sigma</th>\n",
       "      <th>d</th>\n",
       "      <th>tol</th>\n",
       "      <th>iterations</th>\n",
       "      <th>noise</th>\n",
       "      <th>blur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-Images/Baboon.bmp</td>\n",
       "      <td>(7, 3)</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>31.622777</td>\n",
       "      <td>(7, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image deblur_kernel alpha beta0 beta1 sigma  d tol  \\\n",
       "0  0-Images/Baboon.bmp        (7, 3)   100     1     1     2  1   0   \n",
       "\n",
       "  iterations      noise    blur  \n",
       "0         10  31.622777  (7, 3)  "
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATASET_PATH = PATH / pathlib.Path('dataset.pkl')\n",
    "dataset = make_dataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n"
     ]
    }
   ],
   "source": [
    "begin = 0\n",
    "# dataset = pandas.read_pickle(DATASET_PATH)\n",
    "dataset_filtered = dataset.loc[begin:]\n",
    "\n",
    "res_cmp = []\n",
    "# errors_cmp = []\n",
    "for index in tqdm.tqdm(dataset_filtered.index):\n",
    "\n",
    "    params = dataset.loc[index] # Get params from dataset\n",
    "\n",
    "    input = image_from(params)\n",
    "    input_normalized = lasp.utils.normalize(input)\n",
    "\n",
    "    deblur_kernel = lasp.filters.linear.gaussian_filter(\n",
    "        size = dataset.iloc[index]['deblur_kernel'][0],\n",
    "        sigma = dataset.iloc[index]['deblur_kernel'][1]\n",
    "    ) # Not use in function\n",
    "\n",
    "    # Hyper-parameters\n",
    "    alpha = params['alpha']\n",
    "    beta0 = params['beta0']\n",
    "    beta1 = params['beta1']\n",
    "    sigma = params['sigma']\n",
    "    d = params['d']\n",
    "\n",
    "    # Iterative parameters\n",
    "    tol = params['tol']\n",
    "    iterations = params['iterations']\n",
    "\n",
    "    res_deconv = mumford_shah_deconv_v3(\n",
    "        input_normalized, deblur_kernel,\n",
    "        alpha, beta0, sigma,\n",
    "        iterations, tol\n",
    "    )\n",
    "\n",
    "    res_fsr = mumford_shah_fsr(\n",
    "        input_normalized, deblur_kernel,\n",
    "        alpha, beta0, beta1, sigma, d,\n",
    "        iterations, tol, gamma=1e-16\n",
    "    )\n",
    "    \n",
    "    res_cmp.append(numpy.max(numpy.abs(res_fsr-res_deconv)))\n",
    "    # errors_cmp.append(numpy.max(numpy.abs(errors_v1-errors_v2)))\n",
    "\n",
    "res_cmp = numpy.array(res_cmp)\n",
    "# errors_cmp = numpy.array(errors_cmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.46882506e-12]\n"
     ]
    }
   ],
   "source": [
    "print(res_cmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45713a178c5a966329bc5f3278f046d4b32f51be72879f469edfd7ae44ddee4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
