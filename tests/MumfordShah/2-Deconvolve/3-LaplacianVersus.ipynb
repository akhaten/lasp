{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplacian versus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/Stage-SuperResolution/NAME-REPO.git\n",
    "# !mv NAME-REPO/* .\n",
    "# !rm -rf NAME-REPO\n",
    "# !pip install git+https://github.com/akhaten/lasp.git@COMPLETE-COMMIT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasp module\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../..')\n",
    "\n",
    "import lasp.io\n",
    "import lasp.filters.linear\n",
    "import lasp.noise\n",
    "import lasp.convert\n",
    "import lasp.algorithm.experimental\n",
    "import lasp.thresholding\n",
    "import lasp.differential\n",
    "import lasp.utils\n",
    "\n",
    "# Other\n",
    "\n",
    "import scipy.signal\n",
    "import scipy.io.matlab\n",
    "import numpy\n",
    "import pandas\n",
    "import tqdm\n",
    "import pathlib\n",
    "import matplotlib.pyplot\n",
    "import typing\n",
    "\n",
    "IMAGE_PATH = pathlib.Path('../0-Images')\n",
    "# PATH = pathlib.Path('./3-LaplacianVersus')\n",
    "# if not(PATH.exists()):\n",
    "#     PATH.mkdir()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test On"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian with laplacian filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mumford_shah_deconv_v2(\n",
    "    y: numpy.ndarray, \n",
    "    h: numpy.ndarray, \n",
    "    alpha: float,\n",
    "    beta: float,\n",
    "    sigma: float,\n",
    "    nb_iterations: int,\n",
    "    tolerance: float,\n",
    "    error_history: list[float] = None\n",
    ") -> numpy.ndarray:\n",
    "\n",
    "    \"\"\"Mumford Shah\n",
    "    # TODO: make test\n",
    "    Solve argmin_{x} { (alpha/2) || y - Hx ||^2 + (beta/2) || nabla y ||^2 + || nabla y ||_1\n",
    "\n",
    "    Difference with v1 ?\n",
    "    We use Derivation in fourier space\n",
    "    \"\"\"\n",
    "\n",
    "    kernel2d_id = numpy.pad(numpy.array([[1]]), pad_width=1)\n",
    "\n",
    "    dx_oper = lasp.differential.dx(kernel2d_id)\n",
    "    dx_diag = lasp.utils.fourier_diagonalization(dx_oper, y.shape)\n",
    "    dxT_diag = numpy.conj(dx_diag)\n",
    "\n",
    "    dy_oper = lasp.differential.dy(kernel2d_id)\n",
    "    dy_diag = lasp.utils.fourier_diagonalization(dy_oper, y.shape)\n",
    "    dyT_diag = numpy.conj(dy_diag)\n",
    "\n",
    "    # Build kernel\n",
    "\n",
    "    laplacian = lasp.filters.linear.laplacian()\n",
    "    lap_diag = lasp.utils.fourier_diagonalization(\n",
    "        kernel = laplacian,\n",
    "        shape_out = y.shape \n",
    "    )\n",
    "    # lap_diag = Dxt * Dx + Dyt * Dy\n",
    "    #lap_diag = numpy.abs(Dx)**2 + numpy.abs(Dy)**2\n",
    "   \n",
    "    h_diag = lasp.utils.fourier_diagonalization(\n",
    "        kernel = h,\n",
    "        shape_out = y.shape\n",
    "    )\n",
    "\n",
    "    h2_diag = numpy.abs(h_diag)**2\n",
    "\n",
    "\n",
    "    uker = alpha * h2_diag + (beta+sigma) * lap_diag\n",
    "\n",
    "    rhs1fft = alpha * numpy.conj(h_diag) * numpy.fft.fft2(y)\n",
    "\n",
    "    # Initialization\n",
    "    u = numpy.copy(y) \n",
    "    d_x=numpy.zeros_like(y)\n",
    "    d_y=numpy.zeros_like(y)\n",
    "    b_x=numpy.zeros_like(y)\n",
    "    b_y=numpy.zeros_like(y)\n",
    "\n",
    "    for _ in range(0, nb_iterations):\n",
    "\n",
    "        rhs2fft = sigma*dxT_diag*numpy.fft.fft2(d_x-b_x) \\\n",
    "            + sigma*dyT_diag*numpy.fft.fft2(d_y-b_y)\n",
    "        rhsfft = rhs1fft + rhs2fft\n",
    "\n",
    "        u_prev = numpy.copy(u)\n",
    "\n",
    "        u_fft = rhsfft / uker\n",
    "        u = numpy.real(numpy.fft.ifft2(u_fft))    \n",
    "\n",
    "        err = numpy.linalg.norm(u-u_prev, 'fro') / numpy.linalg.norm(u, 'fro')\n",
    "        \n",
    "        if not(error_history is None):\n",
    "            error_history.append(err)\n",
    "\n",
    "        if err < tolerance:\n",
    "            break\n",
    "        \n",
    "    \n",
    "        u_dx = numpy.real(numpy.fft.ifft2(dx_diag * u_fft))\n",
    "        u_dy = numpy.real(numpy.fft.ifft2(dy_diag * u_fft))\n",
    "\n",
    "        d_x, d_y = lasp.thresholding.multidimensional_soft(\n",
    "            d = numpy.array(\n",
    "                [ \n",
    "                    u_dx + b_x,\n",
    "                    u_dy + b_y \n",
    "                ]\n",
    "            ),\n",
    "            epsilon = 1/sigma\n",
    "        )\n",
    "\n",
    "        b_x += (u_dx - d_x)\n",
    "        b_y += (u_dy - d_y)\n",
    "\n",
    "    u_normalized = lasp.utils.normalize(u)\n",
    "\n",
    "    return u_normalized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian with $\\nabla_{x}^{T}\\nabla_{x}+\\nabla_{y}^{T}\\nabla_{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mumford_shah_deconv_v3(\n",
    "    y: numpy.ndarray, \n",
    "    h: numpy.ndarray, \n",
    "    alpha: float,\n",
    "    beta: float,\n",
    "    sigma: float,\n",
    "    nb_iterations: int,\n",
    "    tolerance: float,\n",
    "    error_history: list[float] = None\n",
    ") -> numpy.ndarray:\n",
    "\n",
    "    \"\"\"Mumford Shah\n",
    "    # TODO: make test\n",
    "    Solve argmin_{x} { (alpha/2) || y - Hx ||^2 + (beta/2) || nabla y ||^2 + || nabla y ||_1\n",
    "\n",
    "    Difference with v1 ?\n",
    "    We use Derivation in fourier space\n",
    "    and we set lap_diag = Dxt * Dx + Dyt * Dy and not laplacia  filter\n",
    "    \"\"\"\n",
    "\n",
    "    kernel2d_id = numpy.pad(numpy.array([[1]]), pad_width=1)\n",
    "\n",
    "    dx_oper = lasp.differential.dx(kernel2d_id)\n",
    "    dx_diag = lasp.utils.fourier_diagonalization(dx_oper, y.shape)\n",
    "    dxT_diag = numpy.conj(dx_diag)\n",
    "\n",
    "    dy_oper = lasp.differential.dy(kernel2d_id)\n",
    "    dy_diag = lasp.utils.fourier_diagonalization(dy_oper, y.shape)\n",
    "    dyT_diag = numpy.conj(dy_diag)\n",
    "\n",
    "    # Build kernel\n",
    "    lap_diag = dxT_diag * dx_diag + dyT_diag * dy_diag\n",
    "   \n",
    "   \n",
    "    h_diag = lasp.utils.fourier_diagonalization(\n",
    "        kernel = h,\n",
    "        shape_out = y.shape\n",
    "    )\n",
    "\n",
    "    h2_diag = numpy.abs(h_diag)**2\n",
    "\n",
    "\n",
    "    uker = alpha * h2_diag + (beta+sigma) * lap_diag\n",
    "\n",
    "    rhs1fft = alpha * numpy.conj(h_diag) * numpy.fft.fft2(y)\n",
    "\n",
    "    # Initialization\n",
    "    u = numpy.copy(y) \n",
    "    d_x=numpy.zeros_like(y)\n",
    "    d_y=numpy.zeros_like(y)\n",
    "    b_x=numpy.zeros_like(y)\n",
    "    b_y=numpy.zeros_like(y)\n",
    "\n",
    "    for _ in range(0, nb_iterations):\n",
    "\n",
    "        rhs2fft = sigma*dxT_diag*numpy.fft.fft2(d_x-b_x) \\\n",
    "            + sigma*dyT_diag*numpy.fft.fft2(d_y-b_y)\n",
    "        rhsfft = rhs1fft + rhs2fft\n",
    "\n",
    "        u_prev = numpy.copy(u)\n",
    "\n",
    "        u_fft = rhsfft / uker\n",
    "        u = numpy.real(numpy.fft.ifft2(u_fft))    \n",
    "\n",
    "        err = numpy.linalg.norm(u-u_prev, 'fro') / numpy.linalg.norm(u, 'fro')\n",
    "        \n",
    "        if not(error_history is None):\n",
    "            error_history.append(err)\n",
    "\n",
    "        if err < tolerance:\n",
    "            break\n",
    "        \n",
    "        u_dx = numpy.real(numpy.fft.ifft2(dx_diag * u_fft))\n",
    "        u_dy = numpy.real(numpy.fft.ifft2(dy_diag * u_fft))\n",
    "\n",
    "        d_x, d_y = lasp.thresholding.multidimensional_soft(\n",
    "            d = numpy.array(\n",
    "                [ \n",
    "                    u_dx + b_x, \n",
    "                    u_dy + b_y \n",
    "                ]\n",
    "            ),\n",
    "            epsilon = 1/sigma\n",
    "        )\n",
    "\n",
    "        b_x += (u_dx - d_x)\n",
    "        b_y += (u_dy - d_y)\n",
    "\n",
    "    u_normalized = lasp.utils.normalize(u)\n",
    "\n",
    "    return u_normalized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_from(params: pandas.Series) -> numpy.ndarray:\n",
    "\n",
    "    image_path = params['image']\n",
    "    blur = params['blur']\n",
    "    noise = params['noise']\n",
    "    \n",
    "    img = lasp.io.read(image_path)\n",
    "    out = numpy.copy(img)\n",
    "\n",
    "    if pandas.notna(blur):\n",
    "        kernel = lasp.filters.linear.gaussian_filter(size=blur[0], sigma=blur[1])\n",
    "        out = scipy.signal.convolve2d(out, kernel, mode='same')\n",
    "    \n",
    "    if pandas.notna(noise):\n",
    "        out = lasp.noise.awgn(out, snr=noise)\n",
    "\n",
    "    return out\n",
    "\n",
    "def add(\n",
    "    dataset: pandas.DataFrame,\n",
    "    image: pathlib.Path,\n",
    "    deblur_kernel: tuple[int, float],\n",
    "    alpha: float,\n",
    "    beta: float,\n",
    "    sigma: float,\n",
    "    tol: float = 10**(-4),\n",
    "    iterations: int = 300,\n",
    "    noise: float = numpy.nan,\n",
    "    blur: tuple[int, float] = numpy.nan\n",
    ") -> pandas.DataFrame:\n",
    "\n",
    "    to_add = pandas.DataFrame(\n",
    "        {\n",
    "            'image' : [image], \n",
    "            'deblur_kernel' : [deblur_kernel], \n",
    "            'alpha' : [alpha], \n",
    "            'beta' : [beta],\n",
    "            'sigma' : [sigma],\n",
    "            'tol' : [tol], \n",
    "            'iterations' : [iterations], \n",
    "            'noise' : [noise],\n",
    "            'blur' : [blur]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return pandas.concat([dataset, to_add], ignore_index=True)\n",
    "\n",
    "def process_from_index(dataset: pandas.DataFrame, index: int) -> tuple[numpy.ndarray, numpy.ndarray]:\n",
    "   \n",
    "\n",
    "    params = dataset.loc[index] # Get params from dataset\n",
    "\n",
    "\n",
    "    out = image_from(params)\n",
    "    normalized = lasp.utils.normalize(out)\n",
    "\n",
    "    deblur_kernel = lasp.filters.linear.gaussian_filter(\n",
    "        size = dataset.iloc[index]['deblur_kernel'][0],\n",
    "        sigma = dataset.iloc[index]['deblur_kernel'][1]\n",
    "    )\n",
    "\n",
    "    # Hyper-parameters\n",
    "    alpha = params['alpha']\n",
    "    beta = params['beta']\n",
    "    sigma = params['sigma']\n",
    "\n",
    "    # Iterative parameters\n",
    "    tol = params['tol']\n",
    "    iterations = params['iterations']\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    res = mumford_shah_deconv_v3(\n",
    "        normalized, deblur_kernel,\n",
    "        alpha, beta, sigma,\n",
    "        iterations, tol, \n",
    "        errors\n",
    "    )\n",
    "\n",
    "    return res, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset() -> pandas.DataFrame:    \n",
    "    \n",
    "\n",
    "    dataset = pandas.DataFrame(\n",
    "        columns = [\n",
    "            'image' , 'deblur_kernel',\n",
    "            'alpha', 'beta', 'sigma', # Hyper-parameters\n",
    "            'tol', 'iterations', # Iterative parameters\n",
    "            'noise',\n",
    "            'blur'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dataset = add(\n",
    "        dataset = dataset, \n",
    "        image = IMAGE_PATH / 'Baboon.bmp', deblur_kernel = (7, 3),\n",
    "        alpha = 100, beta = 1, sigma = 2, \n",
    "        tol = 1e-4, iterations = 300, \n",
    "        noise = lasp.convert.snrdb_to_snr(30),\n",
    "        blur = (7, 3)\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>deblur_kernel</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>sigma</th>\n",
       "      <th>tol</th>\n",
       "      <th>iterations</th>\n",
       "      <th>noise</th>\n",
       "      <th>blur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\0-Images\\Baboon.bmp</td>\n",
       "      <td>(7, 3)</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>300</td>\n",
       "      <td>31.622777</td>\n",
       "      <td>(7, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image deblur_kernel alpha beta sigma     tol iterations  \\\n",
       "0  ..\\0-Images\\Baboon.bmp        (7, 3)   100    1     2  0.0001        300   \n",
       "\n",
       "       noise    blur  \n",
       "0  31.622777  (7, 3)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATASET_PATH = PATH / pathlib.Path('dataset.pkl')\n",
    "dataset = make_dataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.to_pickle(dataset, DATASET_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:12<00:00, 12.99s/it]\n"
     ]
    }
   ],
   "source": [
    "begin = 0\n",
    "# dataset = pandas.read_pickle(DATASET_PATH)\n",
    "dataset_filtered = dataset.loc[begin:]\n",
    "\n",
    "res_cmp = []\n",
    "# errors_cmp = []\n",
    "for index in tqdm.tqdm(dataset_filtered.index):\n",
    "\n",
    "    params = dataset.loc[index] # Get params from dataset\n",
    "\n",
    "\n",
    "    input = image_from(params)\n",
    "    input_normalized = lasp.utils.normalize(input)\n",
    "\n",
    "    deblur_kernel = lasp.filters.linear.gaussian_filter(\n",
    "        size = dataset.iloc[index]['deblur_kernel'][0],\n",
    "        sigma = dataset.iloc[index]['deblur_kernel'][1]\n",
    "    )\n",
    "\n",
    "    # Hyper-parameters\n",
    "    alpha = params['alpha']\n",
    "    beta = params['beta']\n",
    "    sigma = params['sigma']\n",
    "\n",
    "    # Iterative parameters\n",
    "    tol = params['tol']\n",
    "    iterations = params['iterations']\n",
    "\n",
    "    res_v2 = mumford_shah_deconv_v2(\n",
    "        input_normalized, deblur_kernel,\n",
    "        alpha, beta, sigma,\n",
    "        iterations, tol\n",
    "    )\n",
    "    res_v3 = mumford_shah_deconv_v3(\n",
    "        input_normalized, deblur_kernel,\n",
    "        alpha, beta, sigma,\n",
    "        iterations, tol\n",
    "    )\n",
    "    \n",
    "    res_cmp.append(numpy.max(numpy.abs(res_v2-res_v3)))\n",
    "    # errors_cmp.append(numpy.max(numpy.abs(errors_v1-errors_v2)))\n",
    "\n",
    "res_cmp = numpy.array(res_cmp)\n",
    "# errors_cmp = numpy.array(errors_cmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.11022302e-15]\n"
     ]
    }
   ],
   "source": [
    "print(res_cmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45713a178c5a966329bc5f3278f046d4b32f51be72879f469edfd7ae44ddee4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
