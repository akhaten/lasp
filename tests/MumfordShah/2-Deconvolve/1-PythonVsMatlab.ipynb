{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaison between Python and Matlab for deconvolution (and denoising)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/Stage-SuperResolution/NAME-REPO.git\n",
    "# !mv NAME-REPO/* .\n",
    "# !rm -rf NAME-REPO\n",
    "# !pip install git+https://github.com/akhaten/lasp.git@COMPLETE-COMMIT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasp module\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../..')\n",
    "\n",
    "import lasp.io\n",
    "import lasp.filters.linear\n",
    "import lasp.noise\n",
    "import lasp.convert\n",
    "import lasp.algorithm.experimental\n",
    "import lasp.thresholding\n",
    "import lasp.differential\n",
    "import lasp.utils\n",
    "\n",
    "# Other\n",
    "\n",
    "import scipy.signal\n",
    "import scipy.io.matlab\n",
    "import numpy\n",
    "import pandas\n",
    "import tqdm\n",
    "import pathlib\n",
    "import matplotlib.pyplot\n",
    "\n",
    "IMAGE_PATH = pathlib.Path('../0-Images')\n",
    "PYMAT_PATH = pathlib.Path('./1-PythonVsMatlab')\n",
    "if not(PYMAT_PATH.exists()):\n",
    "    PYMAT_PATH.mkdir()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mumford_shah_deconv_v1(\n",
    "    y: numpy.ndarray, \n",
    "    h: numpy.ndarray, \n",
    "    alpha: float,\n",
    "    beta: float,\n",
    "    sigma: float,\n",
    "    nb_iterations: int,\n",
    "    tolerance: float,\n",
    "    error_history: list[float] = None\n",
    ") -> numpy.ndarray:\n",
    "\n",
    "    \"\"\"Mumford Shah\n",
    "    \n",
    "    Solve argmin_{x} { (alpha/2) || y - Hx ||^2 + (beta/2) || nabla y ||^2 + || nabla y ||_1 }\n",
    "    \"\"\"\n",
    "\n",
    "    Dx = lasp.differential.dx\n",
    "    Dy = lasp.differential.dy\n",
    "    Dxt = lasp.differential.dxT\n",
    "    Dyt = lasp.differential.dyT\n",
    "\n",
    "    # Build kernel\n",
    "    uker = numpy.zeros_like(y)\n",
    "\n",
    "    laplacian = lasp.filters.linear.laplacian()\n",
    "    lap_diag = lasp.utils.fourier_diagonalization(\n",
    "        kernel = laplacian,\n",
    "        shape_out = y.shape \n",
    "    )\n",
    "   \n",
    "    h_diag = lasp.utils.fourier_diagonalization(\n",
    "        kernel = h,\n",
    "        shape_out = y.shape\n",
    "    )\n",
    "    \n",
    "\n",
    "    h2_diag = numpy.abs(h_diag)**2\n",
    "\n",
    "\n",
    "    uker = alpha * h2_diag + (beta+sigma) * lap_diag\n",
    "\n",
    "    rhs1fft = alpha * numpy.conj(h_diag) * numpy.fft.fft2(y)\n",
    "\n",
    "    # Initialization\n",
    "    u = numpy.copy(y) \n",
    "    d_x=numpy.zeros_like(y)\n",
    "    d_y=numpy.zeros_like(y)\n",
    "    b_x=numpy.zeros_like(y)\n",
    "    b_y=numpy.zeros_like(y)\n",
    "\n",
    "    for _ in range(0, nb_iterations):\n",
    "\n",
    "        rhs2 = sigma*Dxt(d_x-b_x)+sigma*Dyt(d_y-b_y)\n",
    "        rhsfft = rhs1fft + numpy.fft.fft2(rhs2)\n",
    "\n",
    "        u0=numpy.copy(u)\n",
    "        \n",
    "        u = numpy.real(numpy.fft.ifft2(rhsfft / uker))    \n",
    "\n",
    "        err = numpy.linalg.norm(u-u0, 'fro') / numpy.linalg.norm(u, 'fro')\n",
    "        \n",
    "        if not(error_history is None):\n",
    "            error_history.append(err)\n",
    "\n",
    "        if err < tolerance:\n",
    "            break\n",
    "        \n",
    "        u_dx, u_dy = Dx(u), Dy(u)\n",
    "\n",
    "        d_x, d_y = lasp.thresholding.multidimensional_soft(\n",
    "            d = numpy.array([ u_dx + b_x, u_dy + b_y ]),\n",
    "            epsilon = 1/sigma\n",
    "        )\n",
    "\n",
    "        b_x += (u_dx - d_x)\n",
    "        b_y += (u_dy - d_y)\n",
    "\n",
    "    u_normalized = lasp.utils.normalize(u)\n",
    "\n",
    "    return u_normalized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef process_from_index(dataset: pandas.DataFrame, index: int) -> tuple[numpy.ndarray, numpy.ndarray]:\\n   \\n\\n    params = dataset.loc[index] # Get params from dataset\\n\\n\\n    out = image_from(params)\\n    normalized = lasp.utils.normalize(out)\\n\\n    deblur_kernel = lasp.filters.linear.gaussian_filter(\\n        size = dataset.iloc[index]['deblur_kernel'][0],\\n        sigma = dataset.iloc[index]['deblur_kernel'][1]\\n    )\\n\\n    # Hyper-parameters\\n    alpha = params['alpha']\\n    beta = params['beta']\\n    sigma = params['sigma']\\n\\n    # Iterative parameters\\n    tol = params['tol']\\n    iterations = params['iterations']\\n\\n    errors = []\\n\\n    res = mumford_shah_deconv_v1(\\n        normalized, deblur_kernel,\\n        alpha, beta, sigma,\\n        iterations, tol, \\n        errors\\n    )\\n\\n    return res, errors\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def image_from(params: pandas.Series) -> numpy.ndarray:\n",
    "\n",
    "    image_path = params['image']\n",
    "    blur = params['blur']\n",
    "    noise = params['noise']\n",
    "    \n",
    "    img = lasp.io.read(image_path).astype(numpy.double)\n",
    "    out = numpy.copy(img)\n",
    "\n",
    "    if pandas.notna(blur):\n",
    "        kernel = lasp.filters.linear.gaussian_filter(size=blur[0], sigma=blur[1])\n",
    "        out = scipy.signal.convolve2d(out, kernel, mode='same')\n",
    "    \n",
    "    if pandas.notna(noise):\n",
    "        out = lasp.noise.awgn(out, snr=noise)\n",
    "\n",
    "    return out\n",
    "\n",
    "def add(\n",
    "    dataset: pandas.DataFrame,\n",
    "    image: pathlib.Path,\n",
    "    deblur_kernel: tuple[int, float],\n",
    "    alpha: float,\n",
    "    beta: float,\n",
    "    sigma: float,\n",
    "    tol: float = 10**(-4),\n",
    "    iterations: int = 300,\n",
    "    noise: float = numpy.nan,\n",
    "    blur: tuple[int, float] = numpy.nan\n",
    ") -> pandas.DataFrame:\n",
    "\n",
    "    to_add = pandas.DataFrame(\n",
    "        {\n",
    "            'image' : [image], \n",
    "            'deblur_kernel' : [deblur_kernel], \n",
    "            'alpha' : [alpha], \n",
    "            'beta' : [beta],\n",
    "            'sigma' : [sigma],\n",
    "            'tol' : [tol], \n",
    "            'iterations' : [iterations], \n",
    "            'noise' : [noise],\n",
    "            'blur' : [blur]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return pandas.concat([dataset, to_add], ignore_index=True)\n",
    "\"\"\"\n",
    "def process_from_index(dataset: pandas.DataFrame, index: int) -> tuple[numpy.ndarray, numpy.ndarray]:\n",
    "   \n",
    "\n",
    "    params = dataset.loc[index] # Get params from dataset\n",
    "\n",
    "\n",
    "    out = image_from(params)\n",
    "    normalized = lasp.utils.normalize(out)\n",
    "\n",
    "    deblur_kernel = lasp.filters.linear.gaussian_filter(\n",
    "        size = dataset.iloc[index]['deblur_kernel'][0],\n",
    "        sigma = dataset.iloc[index]['deblur_kernel'][1]\n",
    "    )\n",
    "\n",
    "    # Hyper-parameters\n",
    "    alpha = params['alpha']\n",
    "    beta = params['beta']\n",
    "    sigma = params['sigma']\n",
    "\n",
    "    # Iterative parameters\n",
    "    tol = params['tol']\n",
    "    iterations = params['iterations']\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    res = mumford_shah_deconv_v1(\n",
    "        normalized, deblur_kernel,\n",
    "        alpha, beta, sigma,\n",
    "        iterations, tol, \n",
    "        errors\n",
    "    )\n",
    "\n",
    "    return res, errors\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset() -> pandas.DataFrame:    \n",
    "    \n",
    "\n",
    "    dataset = pandas.DataFrame(\n",
    "        columns = [\n",
    "            'image' , 'deblur_kernel',\n",
    "            'alpha', 'beta', 'sigma', # Hyper-parameters\n",
    "            'tol', 'iterations', # Iterative parameters\n",
    "            'noise',\n",
    "            'blur'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dataset = add(\n",
    "        dataset = dataset, \n",
    "        image = IMAGE_PATH / 'Baboon.bmp', deblur_kernel = (7, 3),\n",
    "        alpha = 100., beta = 1., sigma = 2., \n",
    "        tol = 1e-4, iterations = 300, \n",
    "        noise = lasp.convert.snrdb_to_snr(30),\n",
    "        blur = (7, 3)\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>deblur_kernel</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>sigma</th>\n",
       "      <th>tol</th>\n",
       "      <th>iterations</th>\n",
       "      <th>noise</th>\n",
       "      <th>blur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\0-Images\\Baboon.bmp</td>\n",
       "      <td>(7, 3)</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>300</td>\n",
       "      <td>31.622777</td>\n",
       "      <td>(7, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image deblur_kernel  alpha  beta  sigma     tol  \\\n",
       "0  ..\\0-Images\\Baboon.bmp        (7, 3)  100.0   1.0    2.0  0.0001   \n",
       "\n",
       "  iterations      noise    blur  \n",
       "0        300  31.622777  (7, 3)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH = PYMAT_PATH / pathlib.Path('dataset.pkl')\n",
    "dataset = make_dataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.to_pickle(dataset, DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nMAT_PATH = PYMAT_PATH / \\'datas.mat\\'\\n\\ndef make_mat(dataset: pandas.DataFrame, index: int) -> dict:\\n    datas = dataset.loc[index].to_dict()\\n    img = image_from(dataset.loc[index])\\n    normalized = lasp.utils.normalize(img)\\n    #print(datas.keys())\\n    datas[\\'image\\'] = normalized\\n    datas[\\'deblur_kernel\\'] = lasp.filters.linear.gaussian_filter(\\n        size=datas[\\'deblur_kernel\\'][0],\\n        sigma=datas[\\'deblur_kernel\\'][1]\\n    )\\n    #print(datas[\\'deblur_kernel\\'])\\n    return datas\\n\\nmatlab = make_mat(dataset, index=0)\\nscipy.io.matlab.savemat(MAT_PATH, matlab)\\npc_fixe = pathlib.Path(\\'../../../../Seg_ConVar_M-S_Thd_SIIMS_1/data/datas.mat\\')\\nif pc_fixe.exists():\\n    scipy.io.matlab.savemat(pc_fixe, matlab)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "MAT_PATH = PYMAT_PATH / 'datas.mat'\n",
    "\n",
    "def make_mat(dataset: pandas.DataFrame, index: int) -> dict:\n",
    "    datas = dataset.loc[index].to_dict()\n",
    "    img = image_from(dataset.loc[index])\n",
    "    normalized = lasp.utils.normalize(img)\n",
    "    #print(datas.keys())\n",
    "    datas['image'] = normalized\n",
    "    datas['deblur_kernel'] = lasp.filters.linear.gaussian_filter(\n",
    "        size=datas['deblur_kernel'][0],\n",
    "        sigma=datas['deblur_kernel'][1]\n",
    "    )\n",
    "    #print(datas['deblur_kernel'])\n",
    "    return datas\n",
    "\n",
    "matlab = make_mat(dataset, index=0)\n",
    "scipy.io.matlab.savemat(MAT_PATH, matlab)\n",
    "pc_fixe = pathlib.Path('../../../../Seg_ConVar_M-S_Thd_SIIMS_1/data/datas.mat')\n",
    "if pc_fixe.exists():\n",
    "    scipy.io.matlab.savemat(pc_fixe, matlab)\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = 0\n",
    "dataset = pandas.read_pickle(DATASET_PATH)\n",
    "dataset_filtered = dataset.loc[begin:]\n",
    "\n",
    "RESULTS_PATH = PYMAT_PATH / pathlib.Path('./results')\n",
    "if not(RESULTS_PATH.exists()):\n",
    "    RESULTS_PATH.mkdir()\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "RES_CURRENT_PATH = RESULTS_PATH / str(i)\n",
    "if not(RES_CURRENT_PATH.exists()):\n",
    "    RES_CURRENT_PATH.mkdir()\n",
    "\n",
    "\n",
    "params = dataset_filtered.loc[i] # Get params from dataset\n",
    "\n",
    "out = image_from(params)\n",
    "normalized = lasp.utils.normalize(out)\n",
    "\n",
    "deblur_kernel = lasp.filters.linear.gaussian_filter(\n",
    "    size = dataset_filtered.loc[i]['deblur_kernel'][0],\n",
    "    sigma = dataset_filtered.loc[i]['deblur_kernel'][1]\n",
    ")\n",
    "\n",
    "# Hyper-parameters\n",
    "alpha = params['alpha']\n",
    "beta = params['beta']\n",
    "sigma = params['sigma']\n",
    "\n",
    "# Iterative parameters\n",
    "tol = params['tol']\n",
    "iterations = params['iterations']\n",
    "\n",
    "# Matlab datas\n",
    "matlab = params.to_dict()\n",
    "matlab['image'] = normalized\n",
    "matlab['deblur_kernel'] = deblur_kernel\n",
    "MAT_PATH = PYMAT_PATH / 'datas.mat'\n",
    "scipy.io.matlab.savemat(MAT_PATH, matlab)\n",
    "pc_fixe = pathlib.Path('../../../../Seg_ConVar_M-S_Thd_SIIMS_1/data/datas.mat')\n",
    "if pc_fixe.exists():\n",
    "    scipy.io.matlab.savemat(pc_fixe, matlab)\n",
    "\n",
    "# Algorithm\n",
    "errors = []\n",
    "\n",
    "res = mumford_shah_deconv_v1(\n",
    "    normalized, deblur_kernel,\n",
    "    alpha, beta, sigma,\n",
    "    iterations, tol, \n",
    "    errors\n",
    ")\n",
    "\n",
    "lasp.io.save(res, RES_CURRENT_PATH / 'result.npy')\n",
    "lasp.io.save(res, RES_CURRENT_PATH / 'result.png')\n",
    "lasp.io.save(errors, RES_CURRENT_PATH / 'errors.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison with Matlab results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9976021664879227e-15\n"
     ]
    }
   ],
   "source": [
    "res_mat = scipy.io.matlab.loadmat(PYMAT_PATH / 'uu.mat')['uu']\n",
    "res_py = lasp.io.read(RESULTS_PATH / '0' / 'result.npy')\n",
    "print(numpy.max(numpy.abs(res_py-res_mat)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45713a178c5a966329bc5f3278f046d4b32f51be72879f469edfd7ae44ddee4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
